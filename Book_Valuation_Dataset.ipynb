{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO  # Import BytesIO from the io module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the http adress where the files are recorded.\n",
    "git_path = 'https://github.com/gunony/ML_Book_Valuations/raw/main/datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1 - CONSTITUTION OF THE DATASET BEFORE ANALYSIS AND MACHINE LEARNING\n",
    "As explained in the readme file, the aim of the project is to predict the rating that would be given to a book based on a certain amount of input data. This first part consists of preparing the data and creating the dataset to be used for the ML algorithm, which constitutes the second part of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1 - LOAD THE FILE\n",
    "As first dataset called 'books.csv' is a curation of Goodreads books. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the initial dataset of Books list\n",
    "url = git_path+'books.csv'\n",
    "df_Books = pd.read_csv(url,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Books.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Adding book's genre in the data frame Books\n",
    "\n",
    "The genre of the book (history, novel, poetry, etc.) is a factor that readers take into account when making their choice. We can assume that a philosophy book will be read less than a Harry Potter book. This popularity should have an impact on the rating given by readers.\n",
    "\n",
    "The genre is not included in the initial file. The objective of this step is to therefore add the genre of each books. Goodreads determines a book's genre by crowd-sourcing user shelves. If a number of users shelve a book as \"science,\" for example, then that genre is assigned to the book in their algorithm. This isn't a perfect system, as sometimes users might shelve something as \"science\" when it's actually \"science fiction,\" and so on. For more details : https://help.goodreads.com/s/article/How-can-I-set-my-book-s-genres. \n",
    "\n",
    "The genres of book have been grouped into 10 categories with the score given by each reader. These categories and their respective scores will be added to the initial dataset.\n",
    "\n",
    "The data set related to book’s genres comes from the great work made by Mengting Wan and Julian McAuley. \n",
    "• Mengting Wan, Julian McAuley, \"Item Recommendation on Monotonic Behavior Chains\", in RecSys'18. [bibtex] \n",
    "• Mengting Wan, Rishabh Misra, Ndapa Nakashole, Julian McAuley, \"Fine-Grained Spoiler Detection from Large-Scale Review Corpora\", in ACL'19. [bibtex]\n",
    "\n",
    "All files can be found at this adress https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/byGenre/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the gz file and transform into JSON file \n",
    "def load_data(url):\n",
    "    response = requests.get(url)\n",
    "    with gzip.GzipFile(fileobj=BytesIO(response.content), mode='rb') as fin:\n",
    "        data = [json.loads(line.decode('utf-8')) for line in fin]\n",
    "    return data\n",
    "\n",
    "# Assuming the function is defined\n",
    "URL = 'https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/'\n",
    "books = load_data(os.path.join(URL, 'goodreads_book_genres_initial.json.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the nested JSON data structure books into a dataframe called df_Genre\n",
    "df_Genre = pd.json_normalize(books)\n",
    "\n",
    "# Rename the column with book number - will be necessary for the next steps\n",
    "df_Genre.rename(columns={'book_id': 'bookID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_Genre)\n",
    "df_Genre.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark:\n",
    "For each book was assigned a score for each of the 10 literary genres. The book's genre with the highest score will be recorded in a specific column. For books without genre the code genres.missing will be given. The NaN will be replaced by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with 0 in the dataframe Genre\n",
    "df_Genre= df_Genre.fillna(0)\n",
    "# Define a function to get the title of the column with the highest note\n",
    "def get_highest_note_column(row):\n",
    "    max_note = row[['genres.history, historical fiction, biography', 'genres.fiction', 'genres.fantasy, paranormal',\n",
    "                    'genres.mystery, thriller, crime', 'genres.poetry', 'genres.romance', 'genres.non-fiction',\n",
    "                    'genres.children', 'genres.young-adult', 'genres.comics, graphic']].max()\n",
    "    return row.index[row == max_note][0]\n",
    "# Add a new column 'book_genre' to the dataframe\n",
    "df_Genre['main_genre'] = df_Genre.apply(get_highest_note_column, axis=1)\n",
    "# Replace 0 with 'genres.missing' in the 'book_genre' column\n",
    "df_Genre['main_genre'] = df_Genre['main_genre'].replace(0, 'genres.missing')\n",
    "# Look at the updated dataframe\n",
    "display(df_Genre)\n",
    "df_Genre.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're going to include the data relating to book's genres in the books dataset.\n",
    "\n",
    "# Convert the bookID column in dataframe Genre from object to int64\n",
    "df_Genre['bookID'] = df_Genre['bookID'].astype('int64')\n",
    "# Merge both DataFrames based on the book ID\n",
    "df_Books = pd.merge(df_Books, df_Genre, left_on='bookID', right_on='bookID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the final result of the books dataframe after adding book's genre.\n",
    "df_Books.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarks :\n",
    "In the books dataframe there 14 485 books. Only 12664 books have a book's genre. The remaining 1821 books don't have one. \n",
    "We will replace the NaN of these 1821 books with the number 0.\n",
    "\n",
    "How to explain the absence of this information, there are two possibilities. Either these books are new and readers have not had time to read or categorise them. Or these books have simply never been read. This information will be confirmed by the book's publication date.\n",
    "\n",
    "For the rest of the project, we are going to replace the 'NaN' of these 1824 books with the number zero. We will still be able to find these books by summing the scores of the 10 columns representing the book genres. Or by selecting the 'main_genre' column if there is no result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Calculate the seniority of the books\n",
    "From the Publication date until today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Check if column publication_date is correct \n",
    "for index, row in df_Books.iterrows():\n",
    "    try:\n",
    "        date_obj = datetime.strptime(row['publication_date'], '%m/%d/%Y')\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in row {index}: {e}\")\n",
    "        print(\"Row details:\", row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'publication_date' to datetime with US format\n",
    "df_Books['publication_date'] = pd.to_datetime(df_Books['publication_date'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of months from the Publication date until today\n",
    "today = datetime.today()\n",
    "df_Books['Months_Until_Today'] = (today.year - df_Books['publication_date'].dt.year)*12+(today.month - df_Books['publication_date'].dt.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Books.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Book's language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Books['language_code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarks : \n",
    "There are miscellaneous languages. But english is the most representative as Good reads is a US web site.\n",
    "We are going to group English-language books under a single code eng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Books['language_code'].replace(['en-CA', 'en-GB', 'en-US', 'enm'],'eng', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Work on the authors\n",
    "The authors also have a rating which we will retrieve and add to the books dataset.\n",
    "In the authors column of the Books dataset, some books have several names. The first corresponds to the writer (e.g. Harry Potter: 'J.K. Rowling/Mary GrandPrÃ©'). The other names may be illustrators (in the case of Mary GrandPrÃ©), translators or co-authors. \n",
    "Unfortunately, this is information is not available. For the rest of the project, we will therefore keep only the first name that corresponds to the author or one of the authors. This decision was validated after testing a few books.\n",
    "Information on the authors is available on the following site: https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/byGenre/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the author column to keep only the name of the writer\n",
    "df_Books[['authors','co-authors']] = df_Books['authors'].str.split(pat='/', n=1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the gz file and transform into JSON file \n",
    "def load_data(url):\n",
    "    response = requests.get(url)\n",
    "    with gzip.GzipFile(fileobj=BytesIO(response.content), mode='rb') as fin:\n",
    "        data = [json.loads(line.decode('utf-8')) for line in fin]\n",
    "    return data\n",
    "\n",
    "# Assuming the function is defined\n",
    "URL = 'https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/'\n",
    "books = load_data(os.path.join(URL, 'goodreads_book_authors.json.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the nested JSON data structure books into a dataframe called df_Genre\n",
    "df_Authors = pd.json_normalize(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A look at the dataframe\n",
    "df_Authors.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping dictionnary containing only the columns name and average_rating\n",
    "auteur_map = dict(zip(df_Authors['name'], df_Authors['average_rating']))\n",
    "\n",
    "# Adding Authors rating to df-Books\n",
    "df_Books['author_rating'] = df_Books['authors'].map(auteur_map)\n",
    "\n",
    "# For the authors not in the csv file, we give a note of zero.\n",
    "df_Books['author_rating'] = df_Books['author_rating'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change Dtype of author rating\n",
    "df_Books['author_rating'] = df_Books['author_rating'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is NaN in the column author rating\n",
    "Has_Nan = df_Books['author_rating'].isnull().sum()\n",
    "print(Has_Nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Adding format of the books\n",
    "We add the format of the book (paper, audio,...) from the the file 'goodreads_books.json.gz' which is located on the web site : https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/\n",
    "\n",
    "As the file is large (1.9 GB), it was uploaded and converted into an easier-to-load csv file separately containing only the prinicpal information needed : bookID + Format + isebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Book's format csv file\n",
    "df_BooksFormat = pd.read_csv(r\"C:\\Users\\gunon\\Documents\\bootcamp-main\\3-projects\\ML_Book_Valuations\\datasets\\BooksFormat.csv\", sep=\",\")\n",
    "# What is inside the file\n",
    "df_BooksFormat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve the alert message above\n",
    "df_BooksFormat['format'] = df_BooksFormat['format'].astype (object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BooksFormat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping dictionary containing only BookID and Format from the file BooksList.csv\n",
    "book_format = dict(zip(df_BooksFormat['book_id'], df_BooksFormat['format']))\n",
    "\n",
    "# Add format to the Books dataframe using the map function\n",
    "df_Books['book_format'] = df_Books['bookID'].map(book_format)\n",
    "\n",
    "# Group book's format into two families: audio / books\n",
    "df_Books['book_format'] = df_Books['book_format'].fillna('Unknown Binding')\n",
    "df_Books['book_format'] = df_Books.apply(lambda row: 'audio' if 'audio' in row['publisher'].lower() and\n",
    "                        row['book_format'] == 'Unknown Binding' else row['book_format'], axis=1)\n",
    "df_Books['book_format'] = df_Books['book_format'].replace(['Audio', 'Audio CD', 'audio Cassette', 'Audio Cassette'\n",
    "                        ,'Audiobook', 'MP3 CD'], 'audio')\n",
    "df_Books['book_format'] = df_Books['book_format'].replace(['Unknown Binding'], 'book')\n",
    "df_Books['book_format'] = df_Books['book_format'].apply(lambda x: 'book' if x != 'audio' else x)\n",
    "\n",
    "# get_dummies tranforms categorical data to numbers 0=audio / 1=book\n",
    "df_Books[\"audio=0_book=1\"] = pd.get_dummies(df_Books.book_format, drop_first=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the new columns\n",
    "df_Books['book_format'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Books['audio=0_book=1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 7 : Save the final file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Books dataframe with all data on github\n",
    "df_Books.to_csv(r\"C:\\Users\\gunon\\Documents\\bootcamp-main\\3-projects\\ML_Book_Valuations\\datasets\\Books_Final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
