{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aaec0b3",
   "metadata": {},
   "source": [
    "## Create Dataframe with Authors information and List of all Books on Goodreads\n",
    "The two gz files come from the site https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0b5191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f7ffd8",
   "metadata": {},
   "source": [
    "### Step1 - Create the two data frame\n",
    "Objective : create a specific file with authors informations df_Authors and a file with informations on the books df_BooksList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c662d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the directory of the files\n",
    "DIR = 'C:/Users/gunon/Documents/bootcamp-main/3-projects/ML_Book_Valuations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e7504a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the gz file and transform into JSON file \n",
    "def load_data(file_name, head = 200):\n",
    "    count = 0\n",
    "    data = []\n",
    "    with gzip.open(file_name) as fin:\n",
    "        for l in fin:\n",
    "            d = json.loads(l)\n",
    "            count += 1\n",
    "            data.append(d)\n",
    "            \n",
    "            # break if reaches the 100th line\n",
    "            #if (head is not None) and (count > head):\n",
    "             #   break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5fab8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gz file related to authors\n",
    "authors = load_data(os.path.join(DIR, 'goodreads_book_authors.json.gz'))\n",
    "# Transform the nested JSON data structure books into a dataframe called df_Authors\n",
    "df_Authors = pd.json_normalize(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16241c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>name</th>\n",
       "      <th>ratings_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.98</td>\n",
       "      <td>604031</td>\n",
       "      <td>7</td>\n",
       "      <td>Ronald J. Fields</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.08</td>\n",
       "      <td>626222</td>\n",
       "      <td>28716</td>\n",
       "      <td>Anita Diamant</td>\n",
       "      <td>546796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.92</td>\n",
       "      <td>10333</td>\n",
       "      <td>5075</td>\n",
       "      <td>Barbara Hambly</td>\n",
       "      <td>122118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.68</td>\n",
       "      <td>9212</td>\n",
       "      <td>36262</td>\n",
       "      <td>Jennifer Weiner</td>\n",
       "      <td>888522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.82</td>\n",
       "      <td>149918</td>\n",
       "      <td>96</td>\n",
       "      <td>Nigel Pennick</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829524</th>\n",
       "      <td>4.36</td>\n",
       "      <td>197551</td>\n",
       "      <td>4</td>\n",
       "      <td>Patty Furbush</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829525</th>\n",
       "      <td>4.33</td>\n",
       "      <td>3988103</td>\n",
       "      <td>3</td>\n",
       "      <td>Jim Schlinkman</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829526</th>\n",
       "      <td>4.00</td>\n",
       "      <td>13464507</td>\n",
       "      <td>2</td>\n",
       "      <td>Rich Jolly</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829527</th>\n",
       "      <td>3.31</td>\n",
       "      <td>7427847</td>\n",
       "      <td>1</td>\n",
       "      <td>sr@ mwrGn</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829528</th>\n",
       "      <td>3.70</td>\n",
       "      <td>5401342</td>\n",
       "      <td>11</td>\n",
       "      <td>Barry S. Brown</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>829529 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       average_rating author_id text_reviews_count              name  \\\n",
       "0                3.98    604031                  7  Ronald J. Fields   \n",
       "1                4.08    626222              28716     Anita Diamant   \n",
       "2                3.92     10333               5075    Barbara Hambly   \n",
       "3                3.68      9212              36262   Jennifer Weiner   \n",
       "4                3.82    149918                 96     Nigel Pennick   \n",
       "...               ...       ...                ...               ...   \n",
       "829524           4.36    197551                  4     Patty Furbush   \n",
       "829525           4.33   3988103                  3    Jim Schlinkman   \n",
       "829526           4.00  13464507                  2        Rich Jolly   \n",
       "829527           3.31   7427847                  1         sr@ mwrGn   \n",
       "829528           3.70   5401342                 11    Barry S. Brown   \n",
       "\n",
       "       ratings_count  \n",
       "0                 49  \n",
       "1             546796  \n",
       "2             122118  \n",
       "3             888522  \n",
       "4               1740  \n",
       "...              ...  \n",
       "829524            11  \n",
       "829525             6  \n",
       "829526            18  \n",
       "829527            13  \n",
       "829528            43  \n",
       "\n",
       "[829529 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A look at the data frame\n",
    "df_Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf6a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gz file related to BookList\n",
    "books = load_data(os.path.join(DIR, 'goodreads_books.json.gz'))\n",
    "# Transform the nested JSON data structure books into a dataframe called df_BooksList\n",
    "df_BooksList = pd.json_normalize(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f5611eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>series</th>\n",
       "      <th>country_code</th>\n",
       "      <th>language_code</th>\n",
       "      <th>popular_shelves</th>\n",
       "      <th>asin</th>\n",
       "      <th>is_ebook</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>kindle_asin</th>\n",
       "      <th>...</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>edition_information</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>url</th>\n",
       "      <th>image_url</th>\n",
       "      <th>book_id</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_id</th>\n",
       "      <th>title</th>\n",
       "      <th>title_without_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0312853122</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td></td>\n",
       "      <td>[{'count': '3', 'name': 'to-read'}, {'count': ...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>4.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>1984</td>\n",
       "      <td>https://www.goodreads.com/book/show/5333265-w-...</td>\n",
       "      <td>https://images.gr-assets.com/books/1310220028m...</td>\n",
       "      <td>5333265</td>\n",
       "      <td>3</td>\n",
       "      <td>5400751</td>\n",
       "      <td>W.C. Fields: A Life on Film</td>\n",
       "      <td>W.C. Fields: A Life on Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0743509986</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td></td>\n",
       "      <td>[{'count': '2634', 'name': 'to-read'}, {'count...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>3.23</td>\n",
       "      <td>B000FC0PBC</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>Abridged</td>\n",
       "      <td>2001</td>\n",
       "      <td>https://www.goodreads.com/book/show/1333909.Go...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>1333909</td>\n",
       "      <td>10</td>\n",
       "      <td>1323437</td>\n",
       "      <td>Good Harbor</td>\n",
       "      <td>Good Harbor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>[189911]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '58', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td>B00071IKUY</td>\n",
       "      <td>false</td>\n",
       "      <td>4.03</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Book Club Edition</td>\n",
       "      <td>1987</td>\n",
       "      <td>https://www.goodreads.com/book/show/7327624-th...</td>\n",
       "      <td>https://images.gr-assets.com/books/1304100136m...</td>\n",
       "      <td>7327624</td>\n",
       "      <td>140</td>\n",
       "      <td>8948723</td>\n",
       "      <td>The Unschooled Wizard (Sun Wolf and Starhawk, ...</td>\n",
       "      <td>The Unschooled Wizard (Sun Wolf and Starhawk, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0743294297</td>\n",
       "      <td>3282</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '7615', 'name': 'to-read'}, {'count...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>3.49</td>\n",
       "      <td>B002ENBLOK</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>2009</td>\n",
       "      <td>https://www.goodreads.com/book/show/6066819-be...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>6066819</td>\n",
       "      <td>51184</td>\n",
       "      <td>6243154</td>\n",
       "      <td>Best Friends Forever</td>\n",
       "      <td>Best Friends Forever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0850308712</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td></td>\n",
       "      <td>[{'count': '32', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>3.40</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/287140.Run...</td>\n",
       "      <td>https://images.gr-assets.com/books/1413219371m...</td>\n",
       "      <td>287140</td>\n",
       "      <td>15</td>\n",
       "      <td>278577</td>\n",
       "      <td>Runic Astrology: Starcraft and Timekeeping in ...</td>\n",
       "      <td>Runic Astrology: Starcraft and Timekeeping in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360650</th>\n",
       "      <td>0563553014</td>\n",
       "      <td>3</td>\n",
       "      <td>[618749]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '11', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>4.05</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>BBC Radio Collection</td>\n",
       "      <td>1999</td>\n",
       "      <td>https://www.goodreads.com/book/show/3084038-th...</td>\n",
       "      <td>https://images.gr-assets.com/books/1494763458m...</td>\n",
       "      <td>3084038</td>\n",
       "      <td>12</td>\n",
       "      <td>3115103</td>\n",
       "      <td>This Sceptred Isle, Vol. 10: The Age of Victor...</td>\n",
       "      <td>This Sceptred Isle, Vol. 10: The Age of Victor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360651</th>\n",
       "      <td>178092870X</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '702', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>3.50</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2nd Edition</td>\n",
       "      <td>2015</td>\n",
       "      <td>https://www.goodreads.com/book/show/26168430-s...</td>\n",
       "      <td>https://images.gr-assets.com/books/1440592011m...</td>\n",
       "      <td>26168430</td>\n",
       "      <td>6</td>\n",
       "      <td>46130263</td>\n",
       "      <td>Sherlock Holmes and the July Crisis</td>\n",
       "      <td>Sherlock Holmes and the July Crisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360652</th>\n",
       "      <td>0765197456</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td></td>\n",
       "      <td>[{'count': '37', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>4.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>1996</td>\n",
       "      <td>https://www.goodreads.com/book/show/2342551.Th...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>2342551</td>\n",
       "      <td>36</td>\n",
       "      <td>2349247</td>\n",
       "      <td>The Children's Classic Poetry Collection</td>\n",
       "      <td>The Children's Classic Poetry Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360653</th>\n",
       "      <td>162378140X</td>\n",
       "      <td>17</td>\n",
       "      <td>[658195]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '56', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>4.37</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>2014</td>\n",
       "      <td>https://www.goodreads.com/book/show/22017381-1...</td>\n",
       "      <td>https://images.gr-assets.com/books/1398621236m...</td>\n",
       "      <td>22017381</td>\n",
       "      <td>70</td>\n",
       "      <td>41332799</td>\n",
       "      <td>101 Nights: Volume One (101 Nights, #1-3)</td>\n",
       "      <td>101 Nights: Volume One (101 Nights, #1-3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360654</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td></td>\n",
       "      <td>[{'count': '231', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td>B000W914MC</td>\n",
       "      <td>true</td>\n",
       "      <td>3.52</td>\n",
       "      <td>B000W914MC</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/11419866-t...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>11419866</td>\n",
       "      <td>7</td>\n",
       "      <td>2206102</td>\n",
       "      <td>The Spanish Duke's Virgin Bride (Innocent Mist...</td>\n",
       "      <td>The Spanish Duke's Virgin Bride (Innocent Mist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2360655 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               isbn text_reviews_count    series country_code language_code  \\\n",
       "0        0312853122                  1        []           US                 \n",
       "1        0743509986                  6        []           US                 \n",
       "2                                    7  [189911]           US           eng   \n",
       "3        0743294297               3282        []           US           eng   \n",
       "4        0850308712                  5        []           US                 \n",
       "...             ...                ...       ...          ...           ...   \n",
       "2360650  0563553014                  3  [618749]           US           eng   \n",
       "2360651  178092870X                  2        []           US           eng   \n",
       "2360652  0765197456                  6        []           US                 \n",
       "2360653  162378140X                 17  [658195]           US           eng   \n",
       "2360654                              1        []           US                 \n",
       "\n",
       "                                           popular_shelves        asin  \\\n",
       "0        [{'count': '3', 'name': 'to-read'}, {'count': ...               \n",
       "1        [{'count': '2634', 'name': 'to-read'}, {'count...               \n",
       "2        [{'count': '58', 'name': 'to-read'}, {'count':...  B00071IKUY   \n",
       "3        [{'count': '7615', 'name': 'to-read'}, {'count...               \n",
       "4        [{'count': '32', 'name': 'to-read'}, {'count':...               \n",
       "...                                                    ...         ...   \n",
       "2360650  [{'count': '11', 'name': 'to-read'}, {'count':...               \n",
       "2360651  [{'count': '702', 'name': 'to-read'}, {'count'...               \n",
       "2360652  [{'count': '37', 'name': 'to-read'}, {'count':...               \n",
       "2360653  [{'count': '56', 'name': 'to-read'}, {'count':...               \n",
       "2360654  [{'count': '231', 'name': 'to-read'}, {'count'...  B000W914MC   \n",
       "\n",
       "        is_ebook average_rating kindle_asin  ... publication_month  \\\n",
       "0          false           4.00              ...                 9   \n",
       "1          false           3.23  B000FC0PBC  ...                10   \n",
       "2          false           4.03              ...                     \n",
       "3          false           3.49  B002ENBLOK  ...                 7   \n",
       "4          false           3.40              ...                     \n",
       "...          ...            ...         ...  ...               ...   \n",
       "2360650    false           4.05              ...                 9   \n",
       "2360651    false           3.50              ...                 8   \n",
       "2360652    false           4.00              ...                 8   \n",
       "2360653    false           4.37              ...                 4   \n",
       "2360654     true           3.52  B000W914MC  ...                     \n",
       "\n",
       "          edition_information publication_year  \\\n",
       "0                                         1984   \n",
       "1                    Abridged             2001   \n",
       "2           Book Club Edition             1987   \n",
       "3                                         2009   \n",
       "4                                                \n",
       "...                       ...              ...   \n",
       "2360650  BBC Radio Collection             1999   \n",
       "2360651           2nd Edition             2015   \n",
       "2360652                                   1996   \n",
       "2360653                                   2014   \n",
       "2360654                                          \n",
       "\n",
       "                                                       url  \\\n",
       "0        https://www.goodreads.com/book/show/5333265-w-...   \n",
       "1        https://www.goodreads.com/book/show/1333909.Go...   \n",
       "2        https://www.goodreads.com/book/show/7327624-th...   \n",
       "3        https://www.goodreads.com/book/show/6066819-be...   \n",
       "4        https://www.goodreads.com/book/show/287140.Run...   \n",
       "...                                                    ...   \n",
       "2360650  https://www.goodreads.com/book/show/3084038-th...   \n",
       "2360651  https://www.goodreads.com/book/show/26168430-s...   \n",
       "2360652  https://www.goodreads.com/book/show/2342551.Th...   \n",
       "2360653  https://www.goodreads.com/book/show/22017381-1...   \n",
       "2360654  https://www.goodreads.com/book/show/11419866-t...   \n",
       "\n",
       "                                                 image_url   book_id  \\\n",
       "0        https://images.gr-assets.com/books/1310220028m...   5333265   \n",
       "1        https://s.gr-assets.com/assets/nophoto/book/11...   1333909   \n",
       "2        https://images.gr-assets.com/books/1304100136m...   7327624   \n",
       "3        https://s.gr-assets.com/assets/nophoto/book/11...   6066819   \n",
       "4        https://images.gr-assets.com/books/1413219371m...    287140   \n",
       "...                                                    ...       ...   \n",
       "2360650  https://images.gr-assets.com/books/1494763458m...   3084038   \n",
       "2360651  https://images.gr-assets.com/books/1440592011m...  26168430   \n",
       "2360652  https://s.gr-assets.com/assets/nophoto/book/11...   2342551   \n",
       "2360653  https://images.gr-assets.com/books/1398621236m...  22017381   \n",
       "2360654  https://s.gr-assets.com/assets/nophoto/book/11...  11419866   \n",
       "\n",
       "        ratings_count   work_id  \\\n",
       "0                   3   5400751   \n",
       "1                  10   1323437   \n",
       "2                 140   8948723   \n",
       "3               51184   6243154   \n",
       "4                  15    278577   \n",
       "...               ...       ...   \n",
       "2360650            12   3115103   \n",
       "2360651             6  46130263   \n",
       "2360652            36   2349247   \n",
       "2360653            70  41332799   \n",
       "2360654             7   2206102   \n",
       "\n",
       "                                                     title  \\\n",
       "0                              W.C. Fields: A Life on Film   \n",
       "1                                              Good Harbor   \n",
       "2        The Unschooled Wizard (Sun Wolf and Starhawk, ...   \n",
       "3                                     Best Friends Forever   \n",
       "4        Runic Astrology: Starcraft and Timekeeping in ...   \n",
       "...                                                    ...   \n",
       "2360650  This Sceptred Isle, Vol. 10: The Age of Victor...   \n",
       "2360651                Sherlock Holmes and the July Crisis   \n",
       "2360652           The Children's Classic Poetry Collection   \n",
       "2360653          101 Nights: Volume One (101 Nights, #1-3)   \n",
       "2360654  The Spanish Duke's Virgin Bride (Innocent Mist...   \n",
       "\n",
       "                                      title_without_series  \n",
       "0                              W.C. Fields: A Life on Film  \n",
       "1                                              Good Harbor  \n",
       "2        The Unschooled Wizard (Sun Wolf and Starhawk, ...  \n",
       "3                                     Best Friends Forever  \n",
       "4        Runic Astrology: Starcraft and Timekeeping in ...  \n",
       "...                                                    ...  \n",
       "2360650  This Sceptred Isle, Vol. 10: The Age of Victor...  \n",
       "2360651                Sherlock Holmes and the July Crisis  \n",
       "2360652           The Children's Classic Poetry Collection  \n",
       "2360653          101 Nights: Volume One (101 Nights, #1-3)  \n",
       "2360654  The Spanish Duke's Virgin Bride (Innocent Mist...  \n",
       "\n",
       "[2360655 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A look at the data frame\n",
    "df_BooksList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7b0e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving each dataframe into csv file to reuse it in the following ML project\n",
    "df_Authors.to_csv(r\"C:\\Users\\gunon\\Documents\\bootcamp-main\\3-projects\\ML_Book_Valuations\\Authors.csv\", index=False)\n",
    "df_BooksList.to_csv(r\"C:\\Users\\gunon\\Documents\\bootcamp-main\\3-projects\\ML_Book_Valuations\\BooksList.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1da41",
   "metadata": {},
   "source": [
    "### Step 2 - Analyse the dataframe BooksList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdc0a18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_17508\\1452276226.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_BooksList = pd.read_csv(r\"C:\\Users\\gunon\\Documents\\bootcamp-main\\3-projects\\ML_Book_Valuations\\BooksList.csv\", sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "# Load the df BooksList (very long process of creation at step 1)\n",
    "df_BooksList = pd.read_csv(r\"C:\\Users\\gunon\\Documents\\bootcamp-main\\3-projects\\ML_Book_Valuations\\BooksList.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded1ee50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2360655 entries, 0 to 2360654\n",
      "Data columns (total 29 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   isbn                  object \n",
      " 1   text_reviews_count    float64\n",
      " 2   series                object \n",
      " 3   country_code          object \n",
      " 4   language_code         object \n",
      " 5   popular_shelves       object \n",
      " 6   asin                  object \n",
      " 7   is_ebook              object \n",
      " 8   average_rating        float64\n",
      " 9   kindle_asin           object \n",
      " 10  similar_books         object \n",
      " 11  description           object \n",
      " 12  format                object \n",
      " 13  link                  object \n",
      " 14  authors               object \n",
      " 15  publisher             object \n",
      " 16  num_pages             float64\n",
      " 17  publication_day       float64\n",
      " 18  isbn13                object \n",
      " 19  publication_month     float64\n",
      " 20  edition_information   object \n",
      " 21  publication_year      float64\n",
      " 22  url                   object \n",
      " 23  image_url             object \n",
      " 24  book_id               int64  \n",
      " 25  ratings_count         float64\n",
      " 26  work_id               float64\n",
      " 27  title                 object \n",
      " 28  title_without_series  object \n",
      "dtypes: float64(8), int64(1), object(20)\n",
      "memory usage: 522.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_BooksList.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb31965",
   "metadata": {},
   "source": [
    "### Conclusion of the analyse of the df_example\n",
    " 1/ create a specific dataframe related to popular shelves with 'book_id','isbn13'and'title' \n",
    " \n",
    " 2/ create a new dataframe (light) by droppping the useless columns\n",
    " \n",
    " 3/ Expand the data in the column authors into different columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac917b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/Create a dataframe from the popular shelves columns\n",
    "df_shelves = df_BooksList[['book_id','isbn13','title','popular_shelves']].copy()\n",
    "df_shelves.to_csv(r\"C:\\Users\\gunon\\Documents\\bootcamp-main\\3-projects\\ML_Book_Valuations\\Shelves.csv\", index=False)\n",
    "\n",
    "# 2/Create a dataframe\n",
    "df_BooksList_Light=df_BooksList.drop(columns=['series','popular_shelves','asin','similar_books','description','link',\n",
    "                                              'edition_information','kindle_asin','url','image_url','title_without_series'])\n",
    "# Move the author column to the end of the df\n",
    "#df_BooksList_Light.insert(len(df_BooksList_Light.columns), 'authors', df_BooksList_Light.pop('authors'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7940c6f-431a-4853-a413-ba964b628698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2360655 entries, 0 to 2360654\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   isbn                object \n",
      " 1   text_reviews_count  float64\n",
      " 2   country_code        object \n",
      " 3   language_code       object \n",
      " 4   is_ebook            object \n",
      " 5   average_rating      float64\n",
      " 6   format              object \n",
      " 7   authors             object \n",
      " 8   publisher           object \n",
      " 9   num_pages           float64\n",
      " 10  publication_day     float64\n",
      " 11  isbn13              object \n",
      " 12  publication_month   float64\n",
      " 13  publication_year    float64\n",
      " 14  book_id             int64  \n",
      " 15  ratings_count       float64\n",
      " 16  work_id             float64\n",
      " 17  title               object \n",
      "dtypes: float64(8), int64(1), object(9)\n",
      "memory usage: 324.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_BooksList_Light.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4752d983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2360655 entries, 0 to 2360654\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Dtype \n",
      "---  ------           ----- \n",
      " 0   book_id          int64 \n",
      " 1   isbn13           object\n",
      " 2   title            object\n",
      " 3   popular_shelves  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 72.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_shelves.info()\n",
    "# popular-shelves = book's genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68adf60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'author_id_{i+1}'] = ''\n",
      "C:\\Users\\gunon\\AppData\\Local\\Temp\\ipykernel_19312\\237186722.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'role_{i+1}'] = ''\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>country_code</th>\n",
       "      <th>language_code</th>\n",
       "      <th>is_ebook</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>format</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>...</th>\n",
       "      <th>author_id_76</th>\n",
       "      <th>role_76</th>\n",
       "      <th>author_id_77</th>\n",
       "      <th>role_77</th>\n",
       "      <th>author_id_78</th>\n",
       "      <th>role_78</th>\n",
       "      <th>author_id_79</th>\n",
       "      <th>role_79</th>\n",
       "      <th>author_id_80</th>\n",
       "      <th>role_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0312853122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>[{'author_id': '604031', 'role': ''}]</td>\n",
       "      <td>St. Martin's Press</td>\n",
       "      <td>256.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0743509986</td>\n",
       "      <td>6.0</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>3.23</td>\n",
       "      <td>Audio CD</td>\n",
       "      <td>[{'author_id': '626222', 'role': ''}]</td>\n",
       "      <td>Simon &amp; Schuster Audio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>4.03</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>[{'author_id': '10333', 'role': ''}]</td>\n",
       "      <td>Nelson Doubleday, Inc.</td>\n",
       "      <td>600.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0743294297</td>\n",
       "      <td>3282.0</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>3.49</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>[{'author_id': '9212', 'role': ''}]</td>\n",
       "      <td>Atria Books</td>\n",
       "      <td>368.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0850308712</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>3.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'author_id': '149918', 'role': ''}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360650</th>\n",
       "      <td>0563553014</td>\n",
       "      <td>3.0</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>4.05</td>\n",
       "      <td>Audio Cassette</td>\n",
       "      <td>[{'author_id': '4015', 'role': ''}, {'author_i...</td>\n",
       "      <td>BBC Audiobooks</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360651</th>\n",
       "      <td>178092870X</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>[{'author_id': '2448', 'role': ''}, {'author_i...</td>\n",
       "      <td>MX Publishing</td>\n",
       "      <td>148.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360652</th>\n",
       "      <td>0765197456</td>\n",
       "      <td>6.0</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>[{'author_id': '82312', 'role': 'Editor'}]</td>\n",
       "      <td>Smithmark Publishers</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360653</th>\n",
       "      <td>162378140X</td>\n",
       "      <td>17.0</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>False</td>\n",
       "      <td>4.37</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>[{'author_id': '7789809', 'role': ''}]</td>\n",
       "      <td>Guerrilla Wordfare</td>\n",
       "      <td>306.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360654</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'author_id': '621880', 'role': ''}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2360655 rows Ã— 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               isbn  text_reviews_count country_code language_code is_ebook  \\\n",
       "0        0312853122                 1.0           US           NaN    False   \n",
       "1        0743509986                 6.0           US           NaN    False   \n",
       "2               NaN                 7.0           US           eng    False   \n",
       "3        0743294297              3282.0           US           eng    False   \n",
       "4        0850308712                 5.0           US           NaN    False   \n",
       "...             ...                 ...          ...           ...      ...   \n",
       "2360650  0563553014                 3.0           US           eng    False   \n",
       "2360651  178092870X                 2.0           US           eng    False   \n",
       "2360652  0765197456                 6.0           US           NaN    False   \n",
       "2360653  162378140X                17.0           US           eng    False   \n",
       "2360654         NaN                 1.0           US           NaN     True   \n",
       "\n",
       "         average_rating          format  \\\n",
       "0                  4.00       Paperback   \n",
       "1                  3.23        Audio CD   \n",
       "2                  4.03       Hardcover   \n",
       "3                  3.49       Hardcover   \n",
       "4                  3.40             NaN   \n",
       "...                 ...             ...   \n",
       "2360650            4.05  Audio Cassette   \n",
       "2360651            3.50       Paperback   \n",
       "2360652            4.00       Hardcover   \n",
       "2360653            4.37       Paperback   \n",
       "2360654            3.52             NaN   \n",
       "\n",
       "                                                   authors  \\\n",
       "0                    [{'author_id': '604031', 'role': ''}]   \n",
       "1                    [{'author_id': '626222', 'role': ''}]   \n",
       "2                     [{'author_id': '10333', 'role': ''}]   \n",
       "3                      [{'author_id': '9212', 'role': ''}]   \n",
       "4                    [{'author_id': '149918', 'role': ''}]   \n",
       "...                                                    ...   \n",
       "2360650  [{'author_id': '4015', 'role': ''}, {'author_i...   \n",
       "2360651  [{'author_id': '2448', 'role': ''}, {'author_i...   \n",
       "2360652         [{'author_id': '82312', 'role': 'Editor'}]   \n",
       "2360653             [{'author_id': '7789809', 'role': ''}]   \n",
       "2360654              [{'author_id': '621880', 'role': ''}]   \n",
       "\n",
       "                      publisher  num_pages  ...  author_id_76 role_76  \\\n",
       "0            St. Martin's Press      256.0  ...                         \n",
       "1        Simon & Schuster Audio        NaN  ...                         \n",
       "2        Nelson Doubleday, Inc.      600.0  ...                         \n",
       "3                   Atria Books      368.0  ...                         \n",
       "4                           NaN        NaN  ...                         \n",
       "...                         ...        ...  ...           ...     ...   \n",
       "2360650          BBC Audiobooks        3.0  ...                         \n",
       "2360651           MX Publishing      148.0  ...                         \n",
       "2360652    Smithmark Publishers       96.0  ...                         \n",
       "2360653      Guerrilla Wordfare      306.0  ...                         \n",
       "2360654                     NaN        NaN  ...                         \n",
       "\n",
       "         author_id_77  role_77  author_id_78  role_78  author_id_79 role_79  \\\n",
       "0                                                                             \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3                                                                             \n",
       "4                                                                             \n",
       "...               ...      ...           ...      ...           ...     ...   \n",
       "2360650                                                                       \n",
       "2360651                                                                       \n",
       "2360652                                                                       \n",
       "2360653                                                                       \n",
       "2360654                                                                       \n",
       "\n",
       "        author_id_80 role_80  \n",
       "0                             \n",
       "1                             \n",
       "2                             \n",
       "3                             \n",
       "4                             \n",
       "...              ...     ...  \n",
       "2360650                       \n",
       "2360651                       \n",
       "2360652                       \n",
       "2360653                       \n",
       "2360654                       \n",
       "\n",
       "[2360655 rows x 178 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Code to split the column authors\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Give the name of the dataframe to split\n",
    "df = df_BooksList_Light\n",
    "\n",
    "# Function to parse the string into a list of dictionaries\n",
    "def parse_list_string(text):\n",
    "    try:\n",
    "        return ast.literal_eval(text)\n",
    "    except (SyntaxError, ValueError):\n",
    "        return []\n",
    "\n",
    "# Apply the parse_list_string function to col3 and create a new DataFrame with expanded data\n",
    "expanded_data = df['authors'].apply(parse_list_string)\n",
    "\n",
    "# Determine the maximum number of dictionaries in any cell of col3\n",
    "max_num_dicts = max(expanded_data.apply(len))\n",
    "\n",
    "# Create empty columns for each dictionary key\n",
    "for i in range(max_num_dicts):\n",
    "    df[f'author_id_{i+1}'] = ''\n",
    "    df[f'role_{i+1}'] = ''\n",
    "\n",
    "# Fill in the values from the expanded_data\n",
    "for i, row in enumerate(expanded_data):\n",
    "    for j, d in enumerate(row):\n",
    "        df.at[i, f'author_id_{j+1}'] = d.get('author_id', '')\n",
    "        df.at[i, f'role_{j+1}'] = d.get('role', '')\n",
    "\n",
    "# Drop the original col3 column\n",
    "#df.drop(columns=['authors'], inplace=True)\n",
    "\n",
    "# Display the result\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "161ff8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_BooksList_Light\n",
    "\n",
    "# Function to parse the string into a list of dictionaries\n",
    "def parse_list_string(text):\n",
    "    try:\n",
    "        return ast.literal_eval(text)\n",
    "    except (SyntaxError, ValueError):\n",
    "        return []\n",
    "\n",
    "# Apply the parse_list_string function to the \"authors\" column and create a new DataFrame with expanded data\n",
    "expanded_data = df['authors'].apply(parse_list_string)\n",
    "\n",
    "# Create a list of dictionaries for each row\n",
    "dict_list = []\n",
    "for row in expanded_data:\n",
    "    dict_list.append({f'author_id_{i+1}': d.get('author_id', ''), f'role_{i+1}': d.get('role', '')} for i, d in enumerate(row))\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "expanded_df = pd.DataFrame(dict_list)\n",
    "\n",
    "# Combine the original DataFrame and the expanded DataFrame\n",
    "result_df = pd.concat([df[['isbn', 'text_reviews_count', 'country_code', 'language_code', 'is_ebook','average_rating',\n",
    "                           'format', 'authors', 'publisher', 'num_pages', 'publication_day', 'isbn13','publication_month',\n",
    "                           'publication_year', 'book_id', 'ratings_count', 'work_id', 'title' ]], expanded_df], axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
